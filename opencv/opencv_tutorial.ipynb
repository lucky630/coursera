{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "009a71aa-8cd4-4be6-b75e-e0a09004393e",
   "metadata": {},
   "source": [
    "# OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc8463d-7a46-40f8-8634-62a61b2497c1",
   "metadata": {},
   "source": [
    "##  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029afbf4-8c24-45d5-a65b-25e72e2d22e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3dc778-a293-426d-a675-a135df0e6627",
   "metadata": {},
   "source": [
    "## To read images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5614f44-4de5-4b61-80ce-0b5929a25010",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/cat.jpg')\n",
    "cv.imshow('cat',img)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc2b8a1-17b1-442b-b9f4-0329b8027729",
   "metadata": {},
   "source": [
    "## To read videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18c3db78-61c3-4f48-bacc-169e42ad3804",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv.VideoCapture('Resources/Videos/dog.mp4')\n",
    "while True:\n",
    "    istrue,frame = capture.read()\n",
    "    cv.imshow('dog',frame)\n",
    "    if cv.waitKey(20) & 0xFF==ord('d'):\n",
    "        break\n",
    "capture.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeef51b8-fc70-4475-9252-8949716995c3",
   "metadata": {},
   "source": [
    "## To rescale the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea5a3986-305b-4d9b-b31d-f5d9827fe5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_frame(frame,factor=0.75):\n",
    "    width = int(frame.shape[0] * factor)\n",
    "    height = int(frame.shape[1] * factor)\n",
    "    dimensions = (width,height)\n",
    "    return cv.resize(frame,dimensions,interpolation=cv.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7df1bf7-b4d8-4336-9732-d4ecde140667",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv.VideoCapture('Resources/Videos/dog.mp4')\n",
    "while True:\n",
    "    istrue,frame = capture.read()\n",
    "    resized_frame = rescale_frame(frame)\n",
    "    cv.imshow('dog1',resized_frame)\n",
    "    cv.imshow('dog',frame)\n",
    "    if cv.waitKey(20) & 0xFF==ord('d'):\n",
    "        break\n",
    "capture.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab1a09e-1c5b-4ed0-9a38-0ee1ffe0d9b3",
   "metadata": {},
   "source": [
    "## Draw on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf88c3e2-90c3-45e5-8913-1b133c88a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Blank image\n",
    "blank = np.zeros((500,500,3),dtype='uint8')\n",
    "cv.imshow('blank',blank)\n",
    "\n",
    "##color image\n",
    "blank[100:300,300:500] = 0,0,255\n",
    "cv.imshow('green',blank)\n",
    "\n",
    "##draw Rectangle\n",
    "cv.rectangle(blank,(0,0),(250,250),(0,255,0), thickness=2)\n",
    "cv.imshow('Rectangle',blank)\n",
    "\n",
    "##draw Circle\n",
    "cv.circle(blank,(250,250),80,(0,0,250),thickness=-1)\n",
    "cv.imshow('Circle',blank)\n",
    "\n",
    "## put text\n",
    "cv.putText(blank,'Hello',(255,255),cv.FONT_HERSHEY_TRIPLEX,1.0,(255,0,0),3)\n",
    "cv.imshow('Text',blank)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f0a50a-e9f9-4e8d-9051-4461b695e97e",
   "metadata": {},
   "source": [
    "## 5 Essential Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc8c7fc-65f1-4036-95f0-f4f35006628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/park.jpg')\n",
    "cv.imshow('Cat',img)\n",
    "\n",
    "# convert to grayscale\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('gray',gray)\n",
    "\n",
    "# Blur\n",
    "blur = cv.GaussianBlur(img, (3,3), cv.BORDER_DEFAULT)\n",
    "cv.imshow('Blur',blur)\n",
    "\n",
    "#Edge Cascade\n",
    "canny = cv.Canny(blur,125,175)\n",
    "cv.imshow('canny Edges',canny)\n",
    "\n",
    "# Dilating the image\n",
    "dilated = cv.dilate(canny,(7,7),iterations=2)\n",
    "cv.imshow('Dilated',dilated)\n",
    "\n",
    "# Resize\n",
    "resized = cv.resize(img,(400,400),interpolation=cv.INTER_CUBIC)\n",
    "cv.imshow('Resized',resized)\n",
    "\n",
    "# Cropping\n",
    "cropped = img[50:200,200:500]\n",
    "cv.imshow('cropped',cropped)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70719c1-c65b-49b0-a3c7-87b2c4ce985c",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dab3b1a-bc43-4b72-860b-3810d87aafe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/park.jpg')\n",
    "cv.imshow('Park',img)\n",
    "\n",
    "## Translation- shift the image\n",
    "def translate(img,x,y):\n",
    "    transMat = np.float32([[1,0,x],[0,1,y]])\n",
    "    dimensions = (img.shape[1],img.shape[0])\n",
    "    return cv.warpAffine(img,transMat,dimensions)\n",
    "# -x --> Left\n",
    "# -y --> Up\n",
    "# x --> Right\n",
    "# y --> Down\n",
    "\n",
    "translated = translate(img,100,-50)\n",
    "cv.imshow('traslated',translated)\n",
    "\n",
    "# Rotation\n",
    "def rotate(img,angle, rotPoint=None):\n",
    "    (height,width) = img.shape[:2]\n",
    "    if rotPoint is None:\n",
    "        rotPoint = (width//2,height//2)\n",
    "\n",
    "    rotMat = cv.getRotationMatrix2D(rotPoint,angle,1.0)\n",
    "    dimensions = (width,height)\n",
    "    return cv.warpAffine(img,rotMat,dimensions)\n",
    "\n",
    "rotation = rotate(img,30)\n",
    "cv.imshow('rotation',rotation)\n",
    "\n",
    "# Flip\n",
    "# 0- horizontal Flip\n",
    "# 1- Vertical Flip\n",
    "# -1 - vertically an horizontally both\n",
    "flip = cv.flip(img,0)\n",
    "cv.imshow('flipped',flip)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850e9230-2a5e-46bc-987f-6384bcfc5810",
   "metadata": {},
   "source": [
    "## Contour Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f05363-0a4b-4b1e-92df-d163828c41c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/cats.jpg')\n",
    "cv.imshow('Cats',img)\n",
    "\n",
    "blank = np.zeros(img.shape,dtype='uint8')\n",
    "cv.imshow('Blank',blank)\n",
    "\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray',gray)\n",
    "\n",
    "blur = cv.GaussianBlur(gray, (3,3),cv.BORDER_DEFAULT)\n",
    "cv.imshow('Blur',blur)\n",
    "\n",
    "canny = cv.Canny(blur,125,175)\n",
    "cv.imshow('Canny Edges',canny)\n",
    "\n",
    "ret, thresh = cv.threshold(blur,125,255, cv.THRESH_BINARY)\n",
    "cv.imshow('Thresh',thresh)\n",
    "\n",
    "contours, hierarchies = cv.findContours(thresh, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "print(len(contours))\n",
    "\n",
    "cv.drawContours(blank,contours,-1,(0,255,0),1)\n",
    "cv.imshow('Contours Draws',blank)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73f7d6b-e29b-4ba9-97e7-34e0ca4bceaf",
   "metadata": {},
   "source": [
    "## ColorSpaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2462caf0-0f5b-47d8-9f36-020acb735908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv.imread('Resources/Photos/park.jpg')\n",
    "cv.imshow('Park',img)\n",
    "\n",
    "# BGR to Grayscale\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray',gray)\n",
    "\n",
    "# BGR to HSV\n",
    "hsv = cv.cvtColor(img,cv.COLOR_BGR2HSV)\n",
    "cv.imshow('HSV', hsv)\n",
    "\n",
    "# BGR to LAB\n",
    "lab = cv.cvtColor(img,cv.COLOR_BGR2LAB)\n",
    "cv.imshow('LAb',lab)\n",
    "\n",
    "# BGR to RGB\n",
    "rgb = cv.cvtColor(img,cv.COLOR_BGR2RGB)\n",
    "cv.imshow('RGB',rgb)\n",
    "\n",
    "plt.imshow(rgb)\n",
    "plt.show()\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdf2a5d-3788-4e68-a858-51cd7fc2f803",
   "metadata": {},
   "source": [
    "## Color Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486c6c19-aae3-4263-ba5e-16c53ce05bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/park.jpg')\n",
    "cv.imshow('Park',img)\n",
    "\n",
    "## split color channel\n",
    "b,g,r = cv.split(img)\n",
    "cv.imshow('Blue',b)\n",
    "cv.imshow('Green',g)\n",
    "cv.imshow('Red',r)\n",
    "\n",
    "print(img.shape,b.shape,g.shape,r.shape)\n",
    "\n",
    "## merge them back\n",
    "merged = cv.merge([b,g,r])\n",
    "cv.imshow('Merged Image',merged)\n",
    "\n",
    "blank = np.zeros(img.shape[:2],dtype='uint8')\n",
    "blue = cv.merge([b,blank,blank])\n",
    "green = cv.merge([blank,g,blank])\n",
    "red = cv.merge([blank,blank,r])\n",
    "\n",
    "cv.imshow('Blue',blue)\n",
    "cv.imshow('Green',green)\n",
    "cv.imshow('Red',red)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad2c113-c446-4f2a-9d42-74c3b8b88fd1",
   "metadata": {},
   "source": [
    "## Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8128cf-36d2-45ce-abfc-d0ddee5a5d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/cats.jpg')\n",
    "cv.imshow('Park',img)\n",
    "\n",
    "## Averaging\n",
    "average = cv.blur(img,(7,7))\n",
    "cv.imshow('Average Blur',average)\n",
    "\n",
    "## Gaussian Blur\n",
    "gauss = cv.GaussianBlur(img,(7,7),0)\n",
    "cv.imshow('Gaussian Blur',gauss)\n",
    "\n",
    "## Median Blur\n",
    "median = cv.medianBlur(img,3)\n",
    "cv.imshow('Median Blur',median)\n",
    "\n",
    "## Bilateral\n",
    "## 25 means from how far the pixels can effect the calculations\n",
    "bilateral = cv.bilateralFilter(img,10,35,25)\n",
    "cv.imshow('Bilateral',bilateral)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170fd948-4ae6-487d-9f83-fba3e3820643",
   "metadata": {},
   "source": [
    "## Bitwise Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaf7493-21b5-4926-ab9d-6afb492152ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "blank = np.zeros((500,500),dtype='uint8')\n",
    "\n",
    "rectangle = cv.rectangle(blank.copy(), (30,30), (370,370), 255, -1)\n",
    "circle = cv.circle(blank.copy(), (200,200),200,255,-1)\n",
    "\n",
    "cv.imshow('Rectangle',rectangle)\n",
    "cv.imshow('Circle',circle)\n",
    "\n",
    "## bitwise_And\n",
    "bitwise_and = cv.bitwise_and(rectangle,circle)\n",
    "cv.imshow('Bitwise_AND', bitwise_and)\n",
    "\n",
    "## bitwise_OR\n",
    "bitwise_or = cv.bitwise_or(rectangle,circle)\n",
    "cv.imshow('Bitwise_OR', bitwise_or)\n",
    "\n",
    "## bitwise_XOR\n",
    "bitwise_xor = cv.bitwise_xor(rectangle,circle)\n",
    "cv.imshow('Bitwise_XOR', bitwise_xor)\n",
    "\n",
    "## bitwise_not\n",
    "bitwise_not = cv.bitwise_not(circle)\n",
    "cv.imshow('Bitwise_NOT', bitwise_not)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8b0e9c-512b-44c6-b63b-cf763e1d5df5",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6633c0f3-ed90-41bf-a73e-b15a25fe71f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/cats.jpg')\n",
    "cv.imshow('Park',img)\n",
    "\n",
    "blank = np.zeros(img.shape[:2],dtype='uint8')\n",
    "\n",
    "mask = cv.circle(blank,(img.shape[1]//2,img.shape[0]//2),100,255,-1)\n",
    "cv.imshow('Mask',mask)\n",
    "\n",
    "masked = cv.bitwise_and(img,img,mask=mask)\n",
    "cv.imshow('Masked',masked)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32affa33-3775-4a7a-bd01-e13da4f6e87d",
   "metadata": {},
   "source": [
    "## Color Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b13af-2a7c-4ce1-9686-73b9bed4e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/cats.jpg')\n",
    "cv.imshow('Park',img)\n",
    "\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray',gray)\n",
    "\n",
    "## GrayScale Histogram\n",
    "gray_hist = cv.calcHist([gray],[0],None,[256],[0,256])\n",
    "\n",
    "plt.plot(gray_hist)\n",
    "plt.show()\n",
    "\n",
    "## Color Histogram\n",
    "plt.figure()\n",
    "colors = ('b','g','r')\n",
    "for i,col in enumerate(colors):\n",
    "    hist = cv.calcHist([img],[i],None,[256],[0,256])\n",
    "    plt.plot(hist,color=col)\n",
    "    plt.xlim([0,256])\n",
    "plt.show()\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe8b5e3-4c31-4d87-a662-3dd90a2bdc99",
   "metadata": {},
   "source": [
    "## Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411182c-593f-41d7-afd4-34ab7d0696fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/lady.jpg')\n",
    "cv.imshow('Park',img)\n",
    "\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray',gray)\n",
    "\n",
    "# Simple Thresholding\n",
    "threshold,thresh = cv.threshold(gray,150,255,cv.THRESH_BINARY)\n",
    "cv.imshow('Simpel Threshold',thresh)\n",
    "\n",
    "threshold,thresh_inv = cv.threshold(gray,150,255,cv.THRESH_BINARY_INV)\n",
    "cv.imshow('Simpel Threshold Inverse',thresh_inv)\n",
    "\n",
    "# Adaptive Thresholding\n",
    "## Opencv calculate the threshold based upon kernel size\n",
    "adaptive_thresh = cv.adaptiveThreshold(gray,255,cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY_INV,11,9)\n",
    "cv.imshow('Adaptive Thresholding',adaptive_thresh)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f178eec-903e-47bc-a992-2780823ea045",
   "metadata": {},
   "source": [
    "## Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16891eb-f256-439f-b6e5-af8261682f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/park.jpg')\n",
    "cv.imshow('Park',img)\n",
    "\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray',gray)\n",
    "\n",
    "# Laplacian\n",
    "## calculate the gradient when move from black to white or vice versa then slop changed\n",
    "lap = cv.Laplacian(gray,cv.CV_64F)\n",
    "lap = np.uint8(np.absolute(lap))\n",
    "cv.imshow('Laplacian',lap)\n",
    "\n",
    "# Sobel\n",
    "sobelx = cv.Sobel(gray,cv.CV_64F,1,0)\n",
    "sobely = cv.Sobel(gray,cv.CV_64F,0,1)\n",
    "combined = cv.Sobel(gray,cv.CV_64F,1,1)\n",
    "\n",
    "cv.imshow('Sobel X',sobelx)\n",
    "cv.imshow('Sobel Y',sobely)\n",
    "cv.imshow('Sobel Combined',combined)\n",
    "\n",
    "canny = cv.Canny(gray,125,175)\n",
    "cv.imshow('canny Edges',canny)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
